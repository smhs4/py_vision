#!/usr/bin/env python3

import rospy
import numpy as np
import open3d as o3d
from sensor_msgs.msg import PointCloud2
from geometry_msgs.msg import Pose
import sensor_msgs.point_cloud2 as pc2
from tf.transformations import quaternion_from_matrix

class ZeroShotTracker:
    def __init__(self):
        rospy.init_node('zero_shot_pose_node')
        
        # 1. Configuration
        self.voxel_size = 0.05  # 5mm - better for objects like cups
        # Set this to True if your STL was exported in mm
        self.scale_mm_to_m = False
        
        self.model_path = rospy.get_param('~model_path', 'cup.stl')
        
        # 2. Prepare the STL Model
        rospy.loginfo("Loading and sampling STL...")
        mesh = o3d.io.read_triangle_mesh(self.model_path)
        
        if self.scale_mm_to_m:
            mesh.scale(0.001, center=(0, 0, 0))

        # Turn triangles into points (the "Source")
        self.source_pcd = mesh.sample_points_uniformly(number_of_points=10000)
        self.source_pcd = self.source_pcd.voxel_down_sample(self.voxel_size)
        
        # Estimate normals - Crucial fix for your error
        self.source_pcd.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=self.voxel_size * 2, max_nn=30)
        )
        
        self.current_transform = np.identity(4)
        self.initialized = False
        
        # 3. ROS Pub/Sub
        self.pose_pub = rospy.Publisher('/object_pose', Pose, queue_size=1)
        self.sub = rospy.Subscriber('/sciurus17/camera/depth_registered/points', PointCloud2, self.callback)
        
        rospy.loginfo("Node Ready. Listening for PointCloud...")

    def callback(self, data):
        # 1. Convert ROS -> Open3D
        points = np.array(list(pc2.read_points(data, field_names=("x", "y", "z"), skip_nans=True)))
        if len(points) < 50: return
        
        full_cloud = o3d.geometry.PointCloud()
        full_cloud.points = o3d.utility.Vector3dVector(points)
        
        # 2. CROP (Crucial for speed!)
        # Only look at the table area. Adjust these numbers to match your setup.
        # Format: [min_x, min_y, min_z], [max_x, max_y, max_z]
        bbox = o3d.geometry.AxisAlignedBoundingBox(
            min_bound=np.array([-0.5, -0.5, 0.0]), 
            max_bound=np.array([ 0.5,  0.5, 1.0])
        )
        cropped_cloud = full_cloud.crop(bbox)
        
        if len(cropped_cloud.points) < 100:
            rospy.logwarn_throttle(2, "Scene empty after cropping!")
            return

        # 3. Logic Split
        if not self.initialized:
            # === SLOW SEARCH PHASE (Optimized) ===
            rospy.loginfo_once("Starting Global Search (Subject to freezing)...")
            
            # Use a HUGE voxel size for search (2cm) to make it fast
            search_voxel = self.voxel_size * 4 
            source_down = self.source_pcd.voxel_down_sample(search_voxel)
            target_down = cropped_cloud.voxel_down_sample(search_voxel)
            
            # Recalculate normals for this coarse level
            source_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=search_voxel * 2, max_nn=30))
            target_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=search_voxel * 2, max_nn=30))
            
            # Run RANSAC on the "Low-Res" clouds
            result = self.execute_global_registration(source_down, target_down, search_voxel)
            
            if result.fitness > 0.3: # Only accept if it's a good match
                self.current_transform = result.transformation
                self.initialized = True
                rospy.loginfo("Object Found! Switching to High-Speed Tracking.")
            else:
                rospy.logwarn_throttle(2, "Search failed (Fitness: {:.2f}). Retrying...".format(result.fitness))

        else:
            # === FAST TRACKING PHASE ===
            # Use small voxel size (0.5cm) for precision
            target_fine = cropped_cloud.voxel_down_sample(self.voxel_size)
            target_fine.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=self.voxel_size * 2, max_nn=30))
            
            result = o3d.pipelines.registration.registration_icp(
                self.source_pcd, target_fine, self.voxel_size * 2, 
                self.current_transform,
                o3d.pipelines.registration.TransformationEstimationPointToPlane()
            )
            self.current_transform = result.transformation
            self.publish_pose(self.current_transform)

    def execute_global_registration(self, source, target, voxel_size):
        # Calculate features on the downsampled clouds
        source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
            source, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))
        target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
            target, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))
            
        # RANSAC with relaxed criteria for speed
        return o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
            source, target, source_fpfh, target_fpfh,
            True, voxel_size * 2,
            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),
            3, 
            [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
             o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(voxel_size * 2)],
            o3d.pipelines.registration.RANSACConvergenceCriteria(50000, 0.999) # Reduced iterations to 50k
        )

    def get_fpfh(self, pcd):
        return o3d.pipelines.registration.compute_fpfh_feature(
            pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=self.voxel_size * 5, max_nn=100))

    def publish_pose(self, matrix):
        p = Pose()
        # Extract Translation
        p.position.x, p.position.y, p.position.z = matrix[:3, 3]
        
        # Extract Rotation as Quaternion
        q = quaternion_from_matrix(matrix)
        p.orientation.x, p.orientation.y, p.orientation.z, p.orientation.w = q
        
        self.pose_pub.publish(p)

if __name__ == '__main__':
    try:
        tracker = ZeroShotTracker()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass