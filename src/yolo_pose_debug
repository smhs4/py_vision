#!/usr/bin/env python3

import rospy
import numpy as np
import cv2
import open3d as o3d
import message_filters
import struct
import tf
from sensor_msgs.msg import Image, CameraInfo, PointCloud2, PointField
from geometry_msgs.msg import PoseStamped, Point, Vector3
from visualization_msgs.msg import Marker # <--- FOR VISUAL DEBUGGING
import sensor_msgs.point_cloud2 as pc2
from cv_bridge import CvBridge
from ultralytics import YOLO
from scipy.spatial.transform import Rotation as R

class YoloPcaDebug:
    def __init__(self):
        rospy.init_node('yolo_pca_debug')
        
        # 1. Config
        self.bridge = CvBridge()
        self.yolo = YOLO('src/best.pt') 
        self.step = 3
        self.plane_threshold = 0.006
        self.target_frame = "base_link" 
        
        self.tf_listener = tf.TransformListener()
        self.fx, self.fy, self.cx, self.cy = 600.0, 600.0, 320.0, 240.0
        
        # 2. Publishers
        self.pose_pub = rospy.Publisher('/object_pose', PoseStamped, queue_size=1)
        self.pcl_pub = rospy.Publisher('/yolo/cleaned_cloud', PointCloud2, queue_size=1)
        self.debug_pub = rospy.Publisher('/debug/yolo_view', Image, queue_size=1)
        
        # NEW: Visual Marker to see the PCA direction in RViz
        self.marker_pub = rospy.Publisher('/debug/pca_arrow', Marker, queue_size=1)

        # 3. Subscribers
        self.info_sub = rospy.Subscriber(
            '/sciurus17/camera/color/camera_info', 
            CameraInfo, self.info_callback
        )
        
        rgb_sub = message_filters.Subscriber('/sciurus17/camera/color/image_raw', Image)
        depth_sub = message_filters.Subscriber('/sciurus17/camera/aligned_depth_to_color/image_raw', Image)
        
        self.ts = message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub], 10, 0.1)
        self.ts.registerCallback(self.callback)
        
        rospy.loginfo("PCA Debug Node Ready (No ICP).")

    def info_callback(self, msg):
        k = np.array(msg.K).reshape(3,3)
        self.fx, self.fy, self.cx, self.cy = k[0,0], k[1,1], k[0,2], k[1,2]
        self.info_sub.unregister() 

    def remove_farthest_plane(self, pcd):
        points = np.asarray(pcd.points)
        if len(points) < 50: return pcd

        z_coords = points[:, 2]
        median_z = np.median(z_coords)
        far_indices = np.where(z_coords > median_z)[0]
        
        if len(far_indices) < 20: return pcd

        pcd_far = pcd.select_by_index(far_indices)
        plane_model, inliers = pcd_far.segment_plane(distance_threshold=self.plane_threshold,
                                                     ransac_n=3, num_iterations=500)
        
        [a, b, c, d] = plane_model
        distances = np.abs(np.dot(points, np.array([a, b, c])) + d)
        keep_mask = distances > self.plane_threshold
        
        return pcd.select_by_index(np.where(keep_mask)[0])

    def estimate_pose_pca_only(self, target_pcd, header):
        """
        Pure PCA estimation with Debug Prints
        """
        # 1. Centroid (Average Point)
        points = np.asarray(target_pcd.points)
        centroid = np.mean(points, axis=0)
        
        # 2. PCA (Covariance & Eigenvectors)
        cov_matrix = np.cov(points.T)
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
        
        # Sort: Largest eigenvalue (variance) last -> Reverse to get first
        idx = eigenvalues.argsort()[::-1]
        eigenvectors = eigenvectors[:, idx]
        eigenvalues = eigenvalues[idx]
        
        # Extract Vectors
        # v1: Primary Axis (Length/Height of cup)
        # v2: Secondary Axis (Width)
        # v3: Tertiary Axis (Depth)
        v1 = eigenvectors[:, 0]
        v2 = eigenvectors[:, 1]
        v3 = np.cross(v1, v2)   
        
        # --- DEBUG LOGGING ---
        rospy.loginfo("--- PCA DEBUG ---")
        rospy.loginfo(f"Centroid (Cam Frame): [{centroid[0]:.3f}, {centroid[1]:.3f}, {centroid[2]:.3f}]")
        rospy.loginfo(f"Main Axis (v1):       [{v1[0]:.3f}, {v1[1]:.3f}, {v1[2]:.3f}]")
        rospy.loginfo(f"Variances:            {eigenvalues}")
        
        # --- STABILITY FIX ---
        # PCA vectors are ambiguous (v and -v are mathematically same).
        # If the arrow points "down" (positive Y in camera), flip it up.
        # Check this print to see if it flips back and forth!
        if v1[1] > 0: 
            rospy.loginfo("-> Flipping Axis (Pointing Down -> Up)")
            v1 = -v1
            v3 = -v3 
        
        # Construct Rotation Matrix (Columns = Axes)
        # Map PCA Main Axis -> Object Z (Height)
        R_pca = np.column_stack((v2, v3, v1)) 

        # 4x4 Matrix
        T_out = np.identity(4)
        T_out[:3, 3] = centroid
        T_out[:3, :3] = R_pca
        
        # --- VISUAL DEBUG (RViz Arrow) ---
        self.publish_debug_arrow(centroid, v1, header)
        
        return T_out

    def publish_debug_arrow(self, start, direction, header):
        """ Publishes a Red Arrow in RViz showing PCA Main Axis """
        m = Marker()
        m.header = header
        m.ns = "pca_debug"
        m.id = 0
        m.type = Marker.ARROW
        m.action = Marker.ADD
        
        # Start and End points
        p_start = Point(start[0], start[1], start[2])
        p_end = Point(start[0] + direction[0]*0.15, # 15cm long arrow
                      start[1] + direction[1]*0.15, 
                      start[2] + direction[2]*0.15)
        
        m.points = [p_start, p_end]
        
        m.scale.x = 0.01 # Shaft diameter
        m.scale.y = 0.02 # Head diameter
        m.scale.z = 0.0  # Head length
        
        m.color.r = 1.0
        m.color.a = 1.0
        
        self.marker_pub.publish(m)

    def publish_cloud(self, pcd, header):
        points = np.asarray(pcd.points)
        colors = np.asarray(pcd.colors)
        if len(points) == 0: return

        r = (colors[:, 0] * 255).astype(np.uint32)
        g = (colors[:, 1] * 255).astype(np.uint32)
        b = (colors[:, 2] * 255).astype(np.uint32)
        
        rgb_int = (r << 16) | (g << 8) | (b)
        rgb_float = np.array([struct.unpack('f', struct.pack('I', i))[0] for i in rgb_int])
        
        points_3d = np.column_stack((points[:, 0], points[:, 1], points[:, 2], rgb_float))

        fields = [
            PointField('x', 0, PointField.FLOAT32, 1),
            PointField('y', 4, PointField.FLOAT32, 1),
            PointField('z', 8, PointField.FLOAT32, 1),
            PointField('rgb', 12, PointField.FLOAT32, 1),
        ]
        pc_msg = pc2.create_cloud(header, fields, points_3d)
        self.pcl_pub.publish(pc_msg)

    def callback(self, rgb_msg, depth_msg):
        try:
            cv_rgb = self.bridge.imgmsg_to_cv2(rgb_msg, "bgr8")
            cv_depth = self.bridge.imgmsg_to_cv2(depth_msg, "16UC1")
        except Exception: return

        results = self.yolo(cv_rgb, classes=[0], verbose=False, conf=0.4)
        if not results or not results[0].boxes: return
        box = results[0].boxes.xyxy[0].cpu().numpy().astype(int)
        
        cv2.rectangle(cv_rgb, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
        self.debug_pub.publish(self.bridge.cv2_to_imgmsg(cv_rgb, "bgr8"))

        h, w = cv_depth.shape
        x1, y1 = max(0, box[0]), max(0, box[1])
        x2, y2 = min(w, box[2]), min(h, box[3])

        rgb_roi = cv_rgb[y1:y2:self.step, x1:x2:self.step]
        depth_roi = cv_depth[y1:y2:self.step, x1:x2:self.step]
        if depth_roi.size == 0: return

        h_roi, w_roi = depth_roi.shape
        u_col = np.arange(0, w_roi) * self.step + x1
        v_row = np.arange(0, h_roi) * self.step + y1
        u_map, v_map = np.meshgrid(u_col, v_row)
        z = depth_roi.astype(np.float32) / 1000.0 
        
        valid_mask = (z > 0.1) & (z < 2.0)
        if np.count_nonzero(valid_mask) < 20: return
        
        x = (u_map[valid_mask] - self.cx) * z[valid_mask] / self.fx
        y = (v_map[valid_mask] - self.cy) * z[valid_mask] / self.fy
        z_valid = z[valid_mask]
        
        points = np.stack((x, y, z_valid), axis=-1)
        
        b = rgb_roi[:, :, 0][valid_mask]
        g = rgb_roi[:, :, 1][valid_mask]
        r = rgb_roi[:, :, 2][valid_mask]
        colors = np.stack((r, g, b), axis=-1) / 255.0

        target_pcd = o3d.geometry.PointCloud()
        target_pcd.points = o3d.utility.Vector3dVector(points)
        target_pcd.colors = o3d.utility.Vector3dVector(colors)

        # CLEAN
        target_pcd = self.remove_farthest_plane(target_pcd)
        if len(target_pcd.points) < 10: return
        
        self.publish_cloud(target_pcd, rgb_msg.header)

        # PCA ONLY (No ICP)
        final_transform = self.estimate_pose_pca_only(target_pcd, rgb_msg.header)
        
        # Transform and Publish
        self.publish_ros_pose(final_transform, rgb_msg.header)

    def publish_ros_pose(self, camera_T_object, header):
        try:
            (trans, rot) = self.tf_listener.lookupTransform(
                self.target_frame, header.frame_id, rospy.Time(0)
            )
            
            t_mat = tf.transformations.translation_matrix(trans)
            r_mat = tf.transformations.quaternion_matrix(rot)
            base_T_camera = np.dot(t_mat, r_mat)
            
            base_T_object = np.dot(base_T_camera, camera_T_object)
            
            p = PoseStamped()
            p.header.stamp = rospy.Time.now()
            p.header.frame_id = self.target_frame
            
            p.pose.position.x = base_T_object[0, 3]
            p.pose.position.y = base_T_object[1, 3]
            p.pose.position.z = base_T_object[2, 3]
            
            r = R.from_matrix(base_T_object[:3, :3].copy()) 
            quat = r.as_quat() 
            p.pose.orientation.x = quat[0]
            p.pose.orientation.y = quat[1]
            p.pose.orientation.z = quat[2]
            p.pose.orientation.w = quat[3]
            
            self.pose_pub.publish(p)

        except Exception as e:
            rospy.logwarn_throttle(2, f"TF Error: {e}")

if __name__ == '__main__':
    try:
        YoloPcaDebug()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass